<!DOCTYPE html>
<html lang="en">
<head>
    <style>
        @import "lib/materialize/css/materialize.css";
    </style>
    <style>
        @import "lib/playpausebutton/playpause.css";
        @import "css/styles.css";
        @import "js/toast/toast.css";
        @import "js/loader/loader.css";
        @import "js/tooltip/tooltip.css";
    </style>
    <style>
        body {
            color: black;
        }

        img.figureBig {
            width: 80%;
            height: auto;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        img.figureMedium {
            width: 60%;
            height: auto;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        img.figureSmall {
            width: 40%;
            height: auto;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        li {
            list-style-type: circle;
        !important;
        }
    </style>
    <meta charset="UTF-8">
    <title>DeepViz</title>
    <script src="lib/materialize/js/materialize.js"></script>
    <script src="https://d3js.org/d3.v4.min.js"></script>
    <link rel="stylesheet" src="css/styles.css">
</head>
<body>
<nav class="nav-wrapper indigo">
    <div class="container" style="margin-left: auto;margin-right: auto; width: 100%">
        <a href="#" class="brand-logo">DeepViz: Explaining Long Short-Term Memory Network With High Dimensional Time
            Series Data</a>
    </div>
</nav>

<div style="width: 90%; margin-top: 20px; margin-left: auto; margin-right: auto">
    <div class="row col s12" style="width: fit-content; margin-left: auto; margin-right: auto; ">
        <a href="index.html" class="btn btn-menu" id="video">VIDEO</a>
        <a href="#" class="btn btn-menu" id="article">Use cases</a>
        <a href="demo.html" class="btn btn-menu" id="demo">DEMO</a>
    </div>

    <div style="width: 100%">
        <h5 style="width: fit-content; color: #545454;">High Performance Computing Data: HPC
            health prediction</h5>
        <h6 style="width: fit-content; color: #545454;">Configuration: L16-L16-L12-L12-L8-D8-D4 (L: LSTM, D: Dense)</h6>
        <div style="margin-left: auto; margin-right: auto; width: fit-content">
            <img class="responsive-img overview" src="img/HPC_large_model.png" style="height: 90%">
        </div>
        <div>
            <h6>1) Temporal dependency</h6>
            <img class="responsive-img figureMedium" src="img/three_layers.png">
            <div>Consider the first three layers in the structure above:
                <ul>
                    <li>• The first layer is input, there is no pattern we can observed.</li>
                    <li>• The second layer shows somewhat a pattern learned in the upper part of the
                        node.
                    </li>
                    <li>• The third layer presents more clearly the temporal dependency as we can observe a diagonal
                        pattern.
                    </li>
                </ul>

                As we continue with deeper layers, the patterns become clearer, demonstrating that there exists
                a temporal dependency of the learned model over time.

            </div>
            <br>
            <div>
                <h6>2) Trade off between accuracy and training time</h6>
                <img class="responsive-img figureSmall" src="img/AccuracyvsConfiguration.PNG">
                <div>We experimented three settings:
                    <ul>
                        <li>• Configuration 1 (8-4-2) has two LSTM layers -- with 8 and 4 nodes respectively, and only
                            one Dense layer containing two nodes.
                        </li>
                        <li>• Configuration 2 (8-8-8-4) has two LSTM layers -- eight nodes each, and two Dense layers --
                            with 8 and 4 nodes respectively.
                        </li>
                        <li>• We add another 16-node LSTM layer into Configuration 1 to form a more complex
                            Configuration 3 (16-8-8-8-4).
                        </li>
                    </ul>
                    More complex configuration (Configuration 3) generates smaller cost (MSE=4.57, or 2 degrees
                    different compared to the actual CPU temperature) at the cost of training time.

                    The more complex model yields better outcomes in terms of MSE, but the gain is less remarkable as we
                    push further on the model complexity (from Configuration 2 to Configuration 3).

                </div>
                <br>
                <div>
                    <h6>3) Filtering weights</h6>
                    <img class="responsive-img figureBig" src="img/filter.png"><br>
                    <div>
                        Filtering weights helps to focus on the raw and extracted features with respect to significant
                        contributions to the final prediction result. The above figure shows the model of (L8 - L8 -
                        D8 - D4) with the output gates weight filter threshold set to 0.7.
                    </div>
                    <div>
                        It shows that the predicted CPU temperature strongly depends on other CPU temperatures, the CPU
                        load, and the power consumption.
                        Furthermore, these network contribution also suggest another exploration to improve training
                        time or prediction performance, or could be both.
                    </div>

                </div>
            </div>
            <hr>

            <div style="width: 100%">
                <h5 style="width: fit-content; color: #545454">S&P500 Stock Data: Stock price prediction</h5>
                <h6 style="width: fit-content; color: #545454;">Configuration: L16-L16-L12-L12-L8-D8-D4 (L: LSTM, D:
                    Dense)</h6>
                <div style="margin-left: auto; margin-right: auto; width: fit-content">
                    <img class="responsive-img overview" src="img/stock_large_model_2.png">
                </div>
                The
                dataset covers stock records
                for five weekdays each week,
                in the period of 39 years,
                from 1980 to 2019. Each
                record contains the timestamp, stock price at “Open”,
                “High”, “Low”, “Close”, and
                “Volume” of the stock that
                day. During the training and
                testing process, we utilize
                the attributes of the stock
                price on Monday, Tuesday,
                Wednesday, and Thursday to
                predict Close price for Friday.
            </div><br>
            <div>
                DeepViz model for the S&P500 stock market price dataset through two system snapshots: At the 3rd
                epoch and at the 10th epoch:
                <img class="responsive-img figureBig" src="img/stockFig2.png"><br>
            </div>
            <div>
                <h6>1) Evolution of weights</h6>
                <div>
                    <ul>
                        <li>• Panel B1: The thickness of lines decreases significantly over time,
                            indicating that there is a major reduction in the magnitude of these parameters reduces during the training process,
                            hence less contribution of this node to the next output.
                        </li>
                        <li>• Panel A2: There are several negative weights switch into positive right after the first
                            epoch,
                            resulted in an all-positive set of parameters in later epochs, hence the positive contribution to the following layer.

                        </li>
                        <li>• However in panel B2: Major of the parameters have remarkable changes:
                            The originally thick lines decrease their width, the originally thin, positive lines switch into negative and adjust to
                            the larger magnitude.
                        </li>
                    </ul>
                     There is a corresponding movement in the training - testing loss line chart, where the curve witness a
                    turning point (the 5th or 6th epoch) in both training and testing MSE curves.
                </div>
            </div><br>
            <div>
                <h6>2) Learning process</h6>
                <div>
                    <ul>
                        <li>• Panel A3: In the early stage of training process (epoch 3),
                            the scatterplots for training MSE and testing MSE both contain a vertical formation of outputs.
                            <br>This can be explained by the activation function <b>ReLU</b>: Negative input will
                            result in
                                                                                    zero output,
                            as can be seen in the first, third and fourth nodes in the last Dense layer right before
                            the final output.
                            At this stage, the learning process just started and parameters are not tuned properly.
                        </li>
                        <li>• Panel B3: As we move on to epoch 10, the outputs are now align with the target in better shape. Notice that at the last Dense layer, the only one node has positive weight is the second one from top down, with the outputs align in similar direction as target, whereas the other three nodes possess opposite orientation to the target, hence their negative weights.

                        </li>

                    </ul>

                    This observation correlates with the nature of neural network and machine learning in general: On the process of minimizing loss, there are rewards for positive contributions and penalties for negative contributions.
                    Without <b>proper arrangement and visual representation,</b> we would not be able to discern these
                             visual characteristics of parameters in complex neural networks.
                </div>
            </div>
            <br>

            <hr>

            <div style="width: 100%">
                <h5 style="width: fit-content; color: #545454">US Employment Data: Unemployment rate prediction</h5>
                <h6 style="width: fit-content; color: #545454;">Configuration: L16-L16-L12-L12-L8-D8-D4 (L: LSTM, D:
                    Dense)</h6>
                <div style="margin-left: auto; margin-right: auto; width: fit-content">
                    <img class="responsive-img overview" src="img/EMP_large_model.png">
                </div>
            </div>
            <hr>

            <div style="width: 100%">
                <h5 style="width: fit-content; color: #545454">US Employment Data: Unemployment rate prediction</h5>
                <h6 style="width: fit-content; color: #545454;">Configuration: L64-L64-L48-L32-L16-D16-D8-D4 (L: LSTM,
                    D: Dense)</h6>
                <div style="margin-left: auto; margin-right: auto; width: fit-content">
                    <img class="responsive-img" src="img/emp_super_large_model.png">
                </div>
            </div>


        </div>

</body>
<script>
    d3.selectAll(".overview").style("height", window.innerHeight + "px")
</script>
</html>
